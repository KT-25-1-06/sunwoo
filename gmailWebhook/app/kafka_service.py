import json
import asyncio
from aiokafka import AIOKafkaConsumer, AIOKafkaProducer
from settings import settings
from app.events import EmailAnalysisRequestEvent, EmailAnalysisResultEvent, ScheduleCreateEvent
import logging

logger = logging.getLogger(__name__)

class KafkaService:
    def __init__(self):
        self.loop = asyncio.get_event_loop()
        self.producer = None
        self.consumer = None

    async def start(self):
        print(f"ğŸ”„ Kafka Producer ì‹œì‘ ì¤‘... (bootstrap_servers={settings.KAFKA_BOOTSTRAP_SERVERS})")
        self.producer = AIOKafkaProducer(
            loop=self.loop,
            bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS,
            security_protocol=settings.SECURITY_PROTOCOL,
            sasl_mechanism=settings.SASL_MECHANISM,
            sasl_plain_username=settings.SASL_USERNAME,
            sasl_plain_password=settings.SASL_PASSWORD,
            value_serializer=lambda v: json.dumps(v).encode("utf-8"),
        )
        await self.producer.start()
        print("âœ… Kafka Producer ì‹œì‘ ì™„ë£Œ")

        print(f"ğŸ”„ Kafka Consumer ì‹œì‘ ì¤‘... (bootstrap_servers={settings.KAFKA_BOOTSTRAP_SERVERS}, topics={settings.TOPIC_EMAIL_ANALYSIS_RESULT})")
        self.consumer = AIOKafkaConsumer(
            settings.TOPIC_EMAIL_ANALYSIS_RESULT,
            loop=self.loop,
            bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS,
            group_id="gmail-webhook-service",
            security_protocol=settings.SECURITY_PROTOCOL,
            sasl_mechanism=settings.SASL_MECHANISM,
            sasl_plain_username=settings.SASL_USERNAME,
            sasl_plain_password=settings.SASL_PASSWORD,
            value_deserializer=lambda m: json.loads(m.decode("utf-8")),
            auto_offset_reset="earliest",  # ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¶€í„° ì½ê¸°
        )
        await self.consumer.start()
        print(f"âœ… Kafka Consumer ì‹œì‘ ì™„ë£Œ: {settings.TOPIC_EMAIL_ANALYSIS_RESULT} í† í”½ êµ¬ë… ì¤‘")
        
        # êµ¬ë… ì¤‘ì¸ í† í”½ í™•ì¸
        topics = self.consumer.assignment()
        if topics:
            print(f"ğŸ“‹ êµ¬ë… ì¤‘ì¸ í† í”½: {topics}")
        else:
            print("âš ï¸ êµ¬ë… ì¤‘ì¸ í† í”½ì´ ì—†ìŠµë‹ˆë‹¤.")

    async def stop(self):
        if self.producer:
            await self.producer.stop()
        if self.consumer:
            await self.consumer.stop()

    async def produce_email_analysis_request(self, event: EmailAnalysisRequestEvent):
        print(f"ğŸ“¤ ì´ë©”ì¼ ë¶„ì„ ìš”ì²­ ë°œí–‰: email_id={event.email_id}")
        await self.producer.send_and_wait(
            settings.TOPIC_EMAIL_ANALYSIS_REQUEST, event.dict()
        )
        print(f"âœ… ì´ë©”ì¼ ë¶„ì„ ìš”ì²­ ë°œí–‰ ì™„ë£Œ: email_id={event.email_id}")

    async def produce_schedule_create(self, event: ScheduleCreateEvent):
        """ì¼ì • ìƒì„± ì´ë²¤íŠ¸ë¥¼ ë°œí–‰í•©ë‹ˆë‹¤."""
        try:
            await self.producer.send_and_wait(
                settings.TOPIC_SCHEDULE_CREATE,
                event.dict()
            )
            logger.info(f"ì¼ì • ìƒì„± ì´ë²¤íŠ¸ ë°œí–‰ ì™„ë£Œ: {event.dict()}")
        except Exception as e:
            logger.error(f"ì¼ì • ìƒì„± ì´ë²¤íŠ¸ ë°œí–‰ ì‹¤íŒ¨: {str(e)}")
            raise

    async def consume_events(self, handler):
        print("ğŸ”„ Kafka ë©”ì‹œì§€ ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")
        try:
            async for message in self.consumer:
                print(f"ğŸ“¨ ë©”ì‹œì§€ ìˆ˜ì‹ : topic={message.topic}, partition={message.partition}, offset={message.offset}, value={message.value}")
                await handler(message.topic, message.value)
        except Exception as e:
            print(f"âŒ Kafka ë©”ì‹œì§€ ìˆ˜ì‹  ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise e

kafka_service = KafkaService()